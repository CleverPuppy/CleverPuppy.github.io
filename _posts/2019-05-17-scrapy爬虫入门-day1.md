---
layout: post
title:  "scrapy爬虫入门-day1"
date:   2019-05-15 07:34:42 -0500
categories: scrapy
---

>我是如何一步一步学习使用scrapy爬虫框架的

>详细内容可以去[scrapy文档](http://scrapy-chs.readthedocs.io/zh_CN/1.0/index.html)找

## scrapy框架的安装.

>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。

 - 安装python2.7(或者python3)和pip
 - 安装依赖python-dev , lxml , openssl
 - `pip install scrapy`

如果使用的是ubuntu，可以通过添加软件源的方式（最方便的）

    sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 627220E7
    echo 'deb http://archive.scrapy.org/ubuntu scrapy main' | sudo tee /etc/apt/sources.list.d/scrapy.list
    sudo apt-get update && sudo apt-get install scrapy-1.0

## 简单的爬虫

>以爬取[billboardtop100](http://www.billboard.com/charts/hot-100)为例

  1. 创建项目
  ```
  scrapy startproject billboard100
  ```

  这个命令会创建一个名为billboard100的目录
  ```
  billboard100/
├── billboard100
│   ├── __init__.py
│   ├── __init__.pyc
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   ├── settings.pyc
│   └── spiders
│       ├── billboard100_spider.py
│       ├── billboard100_spider.pyc
│       ├── __init__.py
│       └── __init__.pyc
└── scrapy.cfg
  ```

>这里因为我已经创建过spiders/billboard100_spider.py，并且运行过，所以会多出一些文件

  2. 编写第一个爬虫

    - 在billboard100/spiders/创建billboard100_spider.py文件
    ```
        import scrapy

        class Billboard100Spider(scrapy.Spider):
        name = 'billboard100'
        allowed_domains = ['billboard.com']
        start_urls = [
          'http://www.billboard.com/charts/hot-100'
        ]
        def parse(self,response):
          for sel in response.xpath('//article[@data-songtitle]'):
              title = sel.xpath('div[1]/div[@class="chart-row__main-display"]//h2[@class="chart-row__song"]/text()').extract()
              artist = sel.xpath('div[1]/div[@class="chart-row__main-display"]/div[@class="chart-row__container"]/div//*[@class="chart-row__artist"]/text()').extract()
              cover = sel.xpath('div[1]/div[@class="chart-row__main-display"]//div[@class="chart-row__image"]/@data-imagesrc').extract()
              current_week=sel.xpath('div[1]/div[@class="chart-row__main-display"]//span[@class="chart-row__current-week"]/text()').extract()
              last_week=sel.xpath('div[2]/div[1]/div[1]/span[2]/text()').extract()
              weeks_on_chart=sel.xpath('div[2]/div[1]/div[3]/span[2]/text()').extract()
              peak_position=sel.xpath('div[2]/div[1]/div[2]/span[2]/text()').extract()
              print title,artist,cover,current_week,last_week,weeks_on_chart,peak_position
          week_of = response.xpath('//time/text()').extract()
          print week_of
      ```

      >name: 用于区别Spider。 该名字必须是唯一的，您不可以为不同的Spider设定相同的名字。

      >start_urls: 包含了Spider在启动时进行爬取的url列表。 因此，第一个被获取到的页面将是其中之一。 后续的URL则从初始的URL获取到的数据中提取。

      >parse() 是spider的一个方法。 被调用时，每个初始URL完成下载后生成的 Response 对象将会作为唯一的参数传递给该函数。 该方法负责解析返回的
      数据(response data)，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。

  2. 运行爬虫
        ```
        scrapy crawl billboard100
        ```
